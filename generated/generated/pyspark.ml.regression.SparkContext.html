

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>3.8.2.61. pyspark.ml.regression.SparkContext &mdash; PySpark API 1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="PySpark API 1 documentation" href="../../index.html"/>
        <link rel="up" title="3.8. pyspark.ml.regression" href="../pyspark.ml.regression.html"/>
        <link rel="next" title="3.8.2.61.1. pyspark.ml.regression.SparkContext.applicationId" href="pyspark.ml.regression.SparkContext.applicationId.html"/>
        <link rel="prev" title="3.8.2.60.47. pyspark.ml.regression.RandomForestRegressor.write" href="pyspark.ml.regression.RandomForestRegressor.write.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> PySpark API
          

          
          </a>

          
            
            
              <div class="version">
                1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../pyspark.html">1. pyspark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pyspark.sql.html">2. pyspark.sql</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../pyspark.ml.html">3. pyspark.ml</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.html">3.1. pyspark.ml</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.param.html">3.2. pyspark.ml.param</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.feature.html">3.3. pyspark.ml.feature</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.classification.html">3.4. pyspark.ml.classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.clustering.html">3.5. pyspark.ml.clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.linalg.html">3.6. pyspark.ml.linalg</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.recommendation.html">3.7. pyspark.ml.recommendation</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../pyspark.ml.regression.html">3.8. pyspark.ml.regression</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../pyspark.ml.regression.html#functions">3.8.1. Functions</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../pyspark.ml.regression.html#classes">3.8.2. Classes</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.AFTSurvivalRegression.html">3.8.2.1. pyspark.ml.regression.AFTSurvivalRegression</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.AFTSurvivalRegressionModel.html">3.8.2.2. pyspark.ml.regression.AFTSurvivalRegressionModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.DataFrame.html">3.8.2.3. pyspark.ml.regression.DataFrame</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.DecisionTreeModel.html">3.8.2.4. pyspark.ml.regression.DecisionTreeModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.DecisionTreeParams.html">3.8.2.5. pyspark.ml.regression.DecisionTreeParams</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.DecisionTreeRegressionModel.html">3.8.2.6. pyspark.ml.regression.DecisionTreeRegressionModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.DecisionTreeRegressor.html">3.8.2.7. pyspark.ml.regression.DecisionTreeRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.GBTParams.html">3.8.2.8. pyspark.ml.regression.GBTParams</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.GBTRegressionModel.html">3.8.2.9. pyspark.ml.regression.GBTRegressionModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.GBTRegressor.html">3.8.2.10. pyspark.ml.regression.GBTRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.GeneralizedLinearRegression.html">3.8.2.11. pyspark.ml.regression.GeneralizedLinearRegression</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.GeneralizedLinearRegressionModel.html">3.8.2.12. pyspark.ml.regression.GeneralizedLinearRegressionModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.GeneralizedLinearRegressionSummary.html">3.8.2.13. pyspark.ml.regression.GeneralizedLinearRegressionSummary</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.GeneralizedLinearRegressionTrainingSummary.html">3.8.2.14. pyspark.ml.regression.GeneralizedLinearRegressionTrainingSummary</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasCheckpointInterval.html">3.8.2.15. pyspark.ml.regression.HasCheckpointInterval</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasElasticNetParam.html">3.8.2.16. pyspark.ml.regression.HasElasticNetParam</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasFeaturesCol.html">3.8.2.17. pyspark.ml.regression.HasFeaturesCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasFitIntercept.html">3.8.2.18. pyspark.ml.regression.HasFitIntercept</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasHandleInvalid.html">3.8.2.19. pyspark.ml.regression.HasHandleInvalid</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasInputCol.html">3.8.2.20. pyspark.ml.regression.HasInputCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasInputCols.html">3.8.2.21. pyspark.ml.regression.HasInputCols</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasLabelCol.html">3.8.2.22. pyspark.ml.regression.HasLabelCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasMaxIter.html">3.8.2.23. pyspark.ml.regression.HasMaxIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasNumFeatures.html">3.8.2.24. pyspark.ml.regression.HasNumFeatures</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasOutputCol.html">3.8.2.25. pyspark.ml.regression.HasOutputCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasPredictionCol.html">3.8.2.26. pyspark.ml.regression.HasPredictionCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasProbabilityCol.html">3.8.2.27. pyspark.ml.regression.HasProbabilityCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasRawPredictionCol.html">3.8.2.28. pyspark.ml.regression.HasRawPredictionCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasRegParam.html">3.8.2.29. pyspark.ml.regression.HasRegParam</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasSeed.html">3.8.2.30. pyspark.ml.regression.HasSeed</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasSolver.html">3.8.2.31. pyspark.ml.regression.HasSolver</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasStandardization.html">3.8.2.32. pyspark.ml.regression.HasStandardization</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasStepSize.html">3.8.2.33. pyspark.ml.regression.HasStepSize</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasThresholds.html">3.8.2.34. pyspark.ml.regression.HasThresholds</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasTol.html">3.8.2.35. pyspark.ml.regression.HasTol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasVarianceCol.html">3.8.2.36. pyspark.ml.regression.HasVarianceCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.HasWeightCol.html">3.8.2.37. pyspark.ml.regression.HasWeightCol</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.Identifiable.html">3.8.2.38. pyspark.ml.regression.Identifiable</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.IsotonicRegression.html">3.8.2.39. pyspark.ml.regression.IsotonicRegression</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.IsotonicRegressionModel.html">3.8.2.40. pyspark.ml.regression.IsotonicRegressionModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.JavaEstimator.html">3.8.2.41. pyspark.ml.regression.JavaEstimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.JavaMLReadable.html">3.8.2.42. pyspark.ml.regression.JavaMLReadable</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.JavaMLReader.html">3.8.2.43. pyspark.ml.regression.JavaMLReader</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.JavaMLWritable.html">3.8.2.44. pyspark.ml.regression.JavaMLWritable</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.JavaMLWriter.html">3.8.2.45. pyspark.ml.regression.JavaMLWriter</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.JavaModel.html">3.8.2.46. pyspark.ml.regression.JavaModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.JavaWrapper.html">3.8.2.47. pyspark.ml.regression.JavaWrapper</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.LinearRegression.html">3.8.2.48. pyspark.ml.regression.LinearRegression</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.LinearRegressionModel.html">3.8.2.49. pyspark.ml.regression.LinearRegressionModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.LinearRegressionSummary.html">3.8.2.50. pyspark.ml.regression.LinearRegressionSummary</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.LinearRegressionTrainingSummary.html">3.8.2.51. pyspark.ml.regression.LinearRegressionTrainingSummary</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.MLReadable.html">3.8.2.52. pyspark.ml.regression.MLReadable</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.MLReader.html">3.8.2.53. pyspark.ml.regression.MLReader</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.MLWritable.html">3.8.2.54. pyspark.ml.regression.MLWritable</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.MLWriter.html">3.8.2.55. pyspark.ml.regression.MLWriter</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.Param.html">3.8.2.56. pyspark.ml.regression.Param</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.Params.html">3.8.2.57. pyspark.ml.regression.Params</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.RandomForestParams.html">3.8.2.58. pyspark.ml.regression.RandomForestParams</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.RandomForestRegressionModel.html">3.8.2.59. pyspark.ml.regression.RandomForestRegressionModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.RandomForestRegressor.html">3.8.2.60. pyspark.ml.regression.RandomForestRegressor</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">3.8.2.61. pyspark.ml.regression.SparkContext</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.TreeEnsembleModels.html">3.8.2.62. pyspark.ml.regression.TreeEnsembleModels</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.TreeEnsembleParams.html">3.8.2.63. pyspark.ml.regression.TreeEnsembleParams</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.TreeRegressorParams.html">3.8.2.64. pyspark.ml.regression.TreeRegressorParams</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark.ml.regression.TypeConverters.html">3.8.2.65. pyspark.ml.regression.TypeConverters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.tuning.html">3.9. pyspark.ml.tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pyspark.ml.evaluation.html">3.10. pyspark.ml.evaluation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../pyspark.mllib.html">4. pyspark.mllib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pyspark.streaming.html">5. pyspark.streaming</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PySpark API</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../pyspark.ml.html">3. pyspark.ml</a> &raquo;</li>
        
          <li><a href="../pyspark.ml.regression.html">3.8. pyspark.ml.regression</a> &raquo;</li>
        
      <li>3.8.2.61. pyspark.ml.regression.SparkContext</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/generated/generated/pyspark.ml.regression.SparkContext.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pyspark-ml-regression-sparkcontext">
<h1>3.8.2.61. pyspark.ml.regression.SparkContext<a class="headerlink" href="#pyspark-ml-regression-sparkcontext" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="pyspark.ml.regression.SparkContext">
<em class="property">class </em><code class="descclassname">pyspark.ml.regression.</code><code class="descname">SparkContext</code><span class="sig-paren">(</span><em>master=None</em>, <em>appName=None</em>, <em>sparkHome=None</em>, <em>pyFiles=None</em>, <em>environment=None</em>, <em>batchSize=0</em>, <em>serializer=PickleSerializer()</em>, <em>conf=None</em>, <em>gateway=None</em>, <em>jsc=None</em>, <em>profiler_cls=&lt;class 'pyspark.profiler.BasicProfiler'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/context.html#SparkContext"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.regression.SparkContext" title="Permalink to this definition">¶</a></dt>
<dd><p>Main entry point for Spark functionality. A SparkContext represents the
connection to a Spark cluster, and can be used to create L{RDD} and
broadcast variables on that cluster.</p>
<p class="rubric">Attributes</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.applicationId.html#pyspark.ml.regression.SparkContext.applicationId" title="pyspark.ml.regression.SparkContext.applicationId"><code class="xref py py-obj docutils literal"><span class="pre">applicationId</span></code></a></td>
<td>A unique identifier for the Spark application.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.defaultMinPartitions.html#pyspark.ml.regression.SparkContext.defaultMinPartitions" title="pyspark.ml.regression.SparkContext.defaultMinPartitions"><code class="xref py py-obj docutils literal"><span class="pre">defaultMinPartitions</span></code></a></td>
<td>Default min number of partitions for Hadoop RDDs when not given by user</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.defaultParallelism.html#pyspark.ml.regression.SparkContext.defaultParallelism" title="pyspark.ml.regression.SparkContext.defaultParallelism"><code class="xref py py-obj docutils literal"><span class="pre">defaultParallelism</span></code></a></td>
<td>Default level of parallelism to use when not given by user (e.g.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.startTime.html#pyspark.ml.regression.SparkContext.startTime" title="pyspark.ml.regression.SparkContext.startTime"><code class="xref py py-obj docutils literal"><span class="pre">startTime</span></code></a></td>
<td>Return the epoch time when the Spark Context was started.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.version.html#pyspark.ml.regression.SparkContext.version" title="pyspark.ml.regression.SparkContext.version"><code class="xref py py-obj docutils literal"><span class="pre">version</span></code></a></td>
<td>The version of Spark on which this application is running.</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.accumulator.html#pyspark.ml.regression.SparkContext.accumulator" title="pyspark.ml.regression.SparkContext.accumulator"><code class="xref py py-obj docutils literal"><span class="pre">accumulator</span></code></a>(value[,&nbsp;accum_param])</td>
<td>Create an L{Accumulator} with the given initial value, using a given L{AccumulatorParam} helper object to define how to add values of the data type if provided.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.addFile.html#pyspark.ml.regression.SparkContext.addFile" title="pyspark.ml.regression.SparkContext.addFile"><code class="xref py py-obj docutils literal"><span class="pre">addFile</span></code></a>(path)</td>
<td>Add a file to be downloaded with this Spark job on every node.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.addPyFile.html#pyspark.ml.regression.SparkContext.addPyFile" title="pyspark.ml.regression.SparkContext.addPyFile"><code class="xref py py-obj docutils literal"><span class="pre">addPyFile</span></code></a>(path)</td>
<td>Add a .py or .zip dependency for all tasks to be executed on this SparkContext in the future.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.binaryFiles.html#pyspark.ml.regression.SparkContext.binaryFiles" title="pyspark.ml.regression.SparkContext.binaryFiles"><code class="xref py py-obj docutils literal"><span class="pre">binaryFiles</span></code></a>(path[,&nbsp;minPartitions])</td>
<td><div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Experimental</p>
</div>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.binaryRecords.html#pyspark.ml.regression.SparkContext.binaryRecords" title="pyspark.ml.regression.SparkContext.binaryRecords"><code class="xref py py-obj docutils literal"><span class="pre">binaryRecords</span></code></a>(path,&nbsp;recordLength)</td>
<td><div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Experimental</p>
</div>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.broadcast.html#pyspark.ml.regression.SparkContext.broadcast" title="pyspark.ml.regression.SparkContext.broadcast"><code class="xref py py-obj docutils literal"><span class="pre">broadcast</span></code></a>(value)</td>
<td>Broadcast a read-only variable to the cluster, returning a L{Broadcast&lt;pyspark.broadcast.Broadcast&gt;} object for reading it in distributed functions.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.cancelAllJobs.html#pyspark.ml.regression.SparkContext.cancelAllJobs" title="pyspark.ml.regression.SparkContext.cancelAllJobs"><code class="xref py py-obj docutils literal"><span class="pre">cancelAllJobs</span></code></a>()</td>
<td>Cancel all jobs that have been scheduled or are running.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.cancelJobGroup.html#pyspark.ml.regression.SparkContext.cancelJobGroup" title="pyspark.ml.regression.SparkContext.cancelJobGroup"><code class="xref py py-obj docutils literal"><span class="pre">cancelJobGroup</span></code></a>(groupId)</td>
<td>Cancel active jobs for the specified group.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.clearFiles.html#pyspark.ml.regression.SparkContext.clearFiles" title="pyspark.ml.regression.SparkContext.clearFiles"><code class="xref py py-obj docutils literal"><span class="pre">clearFiles</span></code></a>()</td>
<td>Clear the job&#8217;s list of files added by L{addFile} or L{addPyFile} so that they do not get downloaded to any new nodes.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.dump_profiles.html#pyspark.ml.regression.SparkContext.dump_profiles" title="pyspark.ml.regression.SparkContext.dump_profiles"><code class="xref py py-obj docutils literal"><span class="pre">dump_profiles</span></code></a>(path)</td>
<td>Dump the profile stats into directory <cite>path</cite></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.emptyRDD.html#pyspark.ml.regression.SparkContext.emptyRDD" title="pyspark.ml.regression.SparkContext.emptyRDD"><code class="xref py py-obj docutils literal"><span class="pre">emptyRDD</span></code></a>()</td>
<td>Create an RDD that has no partitions or elements.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.getConf.html#pyspark.ml.regression.SparkContext.getConf" title="pyspark.ml.regression.SparkContext.getConf"><code class="xref py py-obj docutils literal"><span class="pre">getConf</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.getLocalProperty.html#pyspark.ml.regression.SparkContext.getLocalProperty" title="pyspark.ml.regression.SparkContext.getLocalProperty"><code class="xref py py-obj docutils literal"><span class="pre">getLocalProperty</span></code></a>(key)</td>
<td>Get a local property set in this thread, or null if it is missing.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.getOrCreate.html#pyspark.ml.regression.SparkContext.getOrCreate" title="pyspark.ml.regression.SparkContext.getOrCreate"><code class="xref py py-obj docutils literal"><span class="pre">getOrCreate</span></code></a>([conf])</td>
<td>Get or instantiate a SparkContext and register it as a singleton object.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.hadoopFile.html#pyspark.ml.regression.SparkContext.hadoopFile" title="pyspark.ml.regression.SparkContext.hadoopFile"><code class="xref py py-obj docutils literal"><span class="pre">hadoopFile</span></code></a>(path,&nbsp;inputFormatClass,&nbsp;keyClass,&nbsp;...)</td>
<td>Read an &#8216;old&#8217; Hadoop InputFormat with arbitrary key and value class from HDFS, a local file system (available on all nodes), or any Hadoop-supported file system URI.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.hadoopRDD.html#pyspark.ml.regression.SparkContext.hadoopRDD" title="pyspark.ml.regression.SparkContext.hadoopRDD"><code class="xref py py-obj docutils literal"><span class="pre">hadoopRDD</span></code></a>(inputFormatClass,&nbsp;keyClass,&nbsp;valueClass)</td>
<td>Read an &#8216;old&#8217; Hadoop InputFormat with arbitrary key and value class, from an arbitrary Hadoop configuration, which is passed in as a Python dict.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.newAPIHadoopFile.html#pyspark.ml.regression.SparkContext.newAPIHadoopFile" title="pyspark.ml.regression.SparkContext.newAPIHadoopFile"><code class="xref py py-obj docutils literal"><span class="pre">newAPIHadoopFile</span></code></a>(path,&nbsp;inputFormatClass,&nbsp;...)</td>
<td>Read a &#8216;new API&#8217; Hadoop InputFormat with arbitrary key and value class from HDFS, a local file system (available on all nodes), or any Hadoop-supported file system URI.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.newAPIHadoopRDD.html#pyspark.ml.regression.SparkContext.newAPIHadoopRDD" title="pyspark.ml.regression.SparkContext.newAPIHadoopRDD"><code class="xref py py-obj docutils literal"><span class="pre">newAPIHadoopRDD</span></code></a>(inputFormatClass,&nbsp;keyClass,&nbsp;...)</td>
<td>Read a &#8216;new API&#8217; Hadoop InputFormat with arbitrary key and value class, from an arbitrary Hadoop configuration, which is passed in as a Python dict.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.parallelize.html#pyspark.ml.regression.SparkContext.parallelize" title="pyspark.ml.regression.SparkContext.parallelize"><code class="xref py py-obj docutils literal"><span class="pre">parallelize</span></code></a>(c[,&nbsp;numSlices])</td>
<td>Distribute a local Python collection to form an RDD.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.pickleFile.html#pyspark.ml.regression.SparkContext.pickleFile" title="pyspark.ml.regression.SparkContext.pickleFile"><code class="xref py py-obj docutils literal"><span class="pre">pickleFile</span></code></a>(name[,&nbsp;minPartitions])</td>
<td>Load an RDD previously saved using L{RDD.saveAsPickleFile} method.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.range.html#pyspark.ml.regression.SparkContext.range" title="pyspark.ml.regression.SparkContext.range"><code class="xref py py-obj docutils literal"><span class="pre">range</span></code></a>(start[,&nbsp;end,&nbsp;step,&nbsp;numSlices])</td>
<td>Create a new RDD of int containing elements from <cite>start</cite> to <cite>end</cite> (exclusive), increased by <cite>step</cite> every element.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.runJob.html#pyspark.ml.regression.SparkContext.runJob" title="pyspark.ml.regression.SparkContext.runJob"><code class="xref py py-obj docutils literal"><span class="pre">runJob</span></code></a>(rdd,&nbsp;partitionFunc[,&nbsp;partitions,&nbsp;...])</td>
<td>Executes the given partitionFunc on the specified set of partitions, returning the result as an array of elements.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.sequenceFile.html#pyspark.ml.regression.SparkContext.sequenceFile" title="pyspark.ml.regression.SparkContext.sequenceFile"><code class="xref py py-obj docutils literal"><span class="pre">sequenceFile</span></code></a>(path[,&nbsp;keyClass,&nbsp;valueClass,&nbsp;...])</td>
<td>Read a Hadoop SequenceFile with arbitrary key and value Writable class from HDFS, a local file system (available on all nodes), or any Hadoop-supported file system URI.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.setCheckpointDir.html#pyspark.ml.regression.SparkContext.setCheckpointDir" title="pyspark.ml.regression.SparkContext.setCheckpointDir"><code class="xref py py-obj docutils literal"><span class="pre">setCheckpointDir</span></code></a>(dirName)</td>
<td>Set the directory under which RDDs are going to be checkpointed.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.setJobGroup.html#pyspark.ml.regression.SparkContext.setJobGroup" title="pyspark.ml.regression.SparkContext.setJobGroup"><code class="xref py py-obj docutils literal"><span class="pre">setJobGroup</span></code></a>(groupId,&nbsp;description[,&nbsp;...])</td>
<td>Assigns a group ID to all the jobs started by this thread until the group ID is set to a different value or cleared.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.setLocalProperty.html#pyspark.ml.regression.SparkContext.setLocalProperty" title="pyspark.ml.regression.SparkContext.setLocalProperty"><code class="xref py py-obj docutils literal"><span class="pre">setLocalProperty</span></code></a>(key,&nbsp;value)</td>
<td>Set a local property that affects jobs submitted from this thread, such as the Spark fair scheduler pool.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.setLogLevel.html#pyspark.ml.regression.SparkContext.setLogLevel" title="pyspark.ml.regression.SparkContext.setLogLevel"><code class="xref py py-obj docutils literal"><span class="pre">setLogLevel</span></code></a>(logLevel)</td>
<td>Control our logLevel.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.setSystemProperty.html#pyspark.ml.regression.SparkContext.setSystemProperty" title="pyspark.ml.regression.SparkContext.setSystemProperty"><code class="xref py py-obj docutils literal"><span class="pre">setSystemProperty</span></code></a>(key,&nbsp;value)</td>
<td>Set a Java system property, such as spark.executor.memory.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.show_profiles.html#pyspark.ml.regression.SparkContext.show_profiles" title="pyspark.ml.regression.SparkContext.show_profiles"><code class="xref py py-obj docutils literal"><span class="pre">show_profiles</span></code></a>()</td>
<td>Print the profile stats to stdout</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.sparkUser.html#pyspark.ml.regression.SparkContext.sparkUser" title="pyspark.ml.regression.SparkContext.sparkUser"><code class="xref py py-obj docutils literal"><span class="pre">sparkUser</span></code></a>()</td>
<td>Get SPARK_USER for user who is running SparkContext.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.statusTracker.html#pyspark.ml.regression.SparkContext.statusTracker" title="pyspark.ml.regression.SparkContext.statusTracker"><code class="xref py py-obj docutils literal"><span class="pre">statusTracker</span></code></a>()</td>
<td>Return <code class="xref py py-class docutils literal"><span class="pre">StatusTracker</span></code> object</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.stop.html#pyspark.ml.regression.SparkContext.stop" title="pyspark.ml.regression.SparkContext.stop"><code class="xref py py-obj docutils literal"><span class="pre">stop</span></code></a>()</td>
<td>Shut down the SparkContext.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.textFile.html#pyspark.ml.regression.SparkContext.textFile" title="pyspark.ml.regression.SparkContext.textFile"><code class="xref py py-obj docutils literal"><span class="pre">textFile</span></code></a>(name[,&nbsp;minPartitions,&nbsp;use_unicode])</td>
<td>Read a text file from HDFS, a local file system (available on all nodes), or any Hadoop-supported file system URI, and return it as an RDD of Strings.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.union.html#pyspark.ml.regression.SparkContext.union" title="pyspark.ml.regression.SparkContext.union"><code class="xref py py-obj docutils literal"><span class="pre">union</span></code></a>(rdds)</td>
<td>Build the union of a list of RDDs.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="pyspark.ml.regression.SparkContext.wholeTextFiles.html#pyspark.ml.regression.SparkContext.wholeTextFiles" title="pyspark.ml.regression.SparkContext.wholeTextFiles"><code class="xref py py-obj docutils literal"><span class="pre">wholeTextFiles</span></code></a>(path[,&nbsp;minPartitions,&nbsp;...])</td>
<td>Read a directory of text files from HDFS, a local file system (available on all nodes), or any  Hadoop-supported file system URI.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="pyspark.ml.regression.SparkContext.applicationId.html" class="btn btn-neutral float-right" title="3.8.2.61.1. pyspark.ml.regression.SparkContext.applicationId" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="pyspark.ml.regression.RandomForestRegressor.write.html" class="btn btn-neutral" title="3.8.2.60.47. pyspark.ml.regression.RandomForestRegressor.write" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>